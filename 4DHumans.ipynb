{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH6h3ljStKEV"
      },
      "source": [
        "# 4DHumans Demo Notebook\n",
        "This a demo notebook for our paper \"4DHumans: Reconstructing and Tracking Humans with Transformers\".\n",
        "\n",
        "<p align=\"left\"><img src=\"https://github.com/shubham-goel/4D-Humans/raw/main/assets/teaser.png\" width=\"800\"></p>\n",
        "\n",
        "<p align=\"left\"><img src=\"https://github.com/brjathu/PHALP/raw/master/assets/imgs/teaser.gif\" width=\"800\"></p>\n",
        "\n",
        "Project webpage: https://shubham-goel.github.io/4dhumans/\n",
        "\n",
        "Github repo: https://github.com/shubham-goel/4D-Humans\n",
        "\n",
        "Instructions:\n",
        "\n",
        "1. Enable the GPU Runtime (Runtime > Change Runtime Type > GPU)\n",
        "2. Clone the repository and install depencencies\n",
        "3. Run the demo\n",
        "4. Visualize the video\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Grc-NDsvJ2d"
      },
      "source": [
        "# Clone the repository and install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHlxjgrdtePu"
      },
      "outputs": [],
      "source": [
        "# Clone the main repo\n",
        "%%capture\n",
        "! git clone https://github.com/shubham-goel/4D-Humans.git 4D-Humans\n",
        "%cd 4D-Humans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "urCqVANctz2s",
        "outputId": "f98d4314-09a5-4227-e71e-b08ebbb16b29"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install -e .[all]\n",
        "!wget https://github.com/classner/up/raw/master/models/3D/basicModel_neutral_lbs_10_207_0_v1.0.0.pkl\n",
        "!mkdir data/\n",
        "!mv basicModel_neutral_lbs_10_207_0_v1.0.0.pkl data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKpHRz1BvdlZ"
      },
      "source": [
        "# Run the demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpu-yVB0vw1N",
        "outputId": "234bc32a-6c5f-43eb-e96c-7fe38ed18518"
      },
      "outputs": [],
      "source": [
        "# run hmr2 on a folder of images\n",
        "!python demo.py \\\n",
        "--img_folder example_data/images \\\n",
        "--out_folder demo_out \\\n",
        "--batch_size=48 --side_view --save_mesh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0BhB4EzwhKb"
      },
      "source": [
        "### Visualize the reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "5L3jrsbLwme3",
        "outputId": "0b57587f-aba5-4976-8667-349f1b17725b"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "import os\n",
        "# https://colab.research.google.com/drive/1Ex4gE5v1bPR3evfhtG7sDHxQGsWwNwby?usp=sharing\n",
        "output_images = [\"demo_out/\" + i for i in os.listdir(\"demo_out/\") if \".png\" in i]\n",
        "for img in output_images:\n",
        "  display(Image(img))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIL8JadpwE0s"
      },
      "source": [
        "# Video Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVSxpGVrePtl"
      },
      "source": [
        "### Install PHALP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4sNUOQZwG82",
        "outputId": "d8ddd141-874b-4f85-c7c2-036d4971eb9a"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/brjathu/PHALP.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQc_CVQRegJT"
      },
      "source": [
        "### Track and visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgkRdPF6yTBC",
        "outputId": "6d7a872c-5cde-46cd-e32a-452ddeb5ece4"
      },
      "outputs": [],
      "source": [
        "!python track.py video.source=\"example_data/videos/gymnasts.mp4\" video.start_frame=10 video.end_frame=60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGLvO4sz5o2S",
        "outputId": "373410d8-7c03-4039-c442-b418ef4c3bd6"
      },
      "outputs": [],
      "source": [
        "# Display the reconstruction video\n",
        "def show_local_mp4_video(file_name, width=640, height=480):\n",
        "  import io\n",
        "  import base64\n",
        "  from IPython.display import HTML\n",
        "  video_encoded = base64.b64encode(io.open(file_name, 'rb').read())\n",
        "  return HTML(data='''<video width=\"{0}\" height=\"{1}\" alt=\"test\" controls>\n",
        "                      <source src=\"data:video/mp4;base64,{2}\" type=\"video/mp4\" />\n",
        "                      </video>'''.format(width, height, video_encoded.decode('ascii')))\n",
        "\n",
        "!ffmpeg -y -hide_banner -loglevel error -i outputs/PHALP_gymnasts.mp4 outputs/PHALP_gymnasts_ffmpeg.mp4\n",
        "show_local_mp4_video('outputs/PHALP_gymnasts_ffmpeg.mp4', width=960, height=540)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualize with Polyscope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle as pkl\n",
        "import gzip\n",
        "# joblib is used to load the model outputs\n",
        "import joblib\n",
        "import polyscope as ps\n",
        "import polyscope.imgui as psim\n",
        "from matplotlib import pyplot as plt\n",
        "import os, sys\n",
        "import numpy as np\n",
        "import cv2\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "sys.path.insert(0, os.path.abspath(\"/scratch/ondemand27/evanpan/motion_instruction/smpl\"))\n",
        "sys.path.insert(0, os.path.abspath(\"/Users/evanpan/Documents/GitHub/Motion_instruction/smpl\"))\n",
        "from smpl_np import SMPLModel\n",
        "# from smpl.smpl_webuser.serialization import load_model\n",
        "# from phalp.utils import smpl_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %matplotlib widget\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "motionData_path = \"./4D-Humans_outputs/results/demo_biggerspin1.pkl\"\n",
        "motiondata = joblib.load(open(motionData_path, \"rb\"))\n",
        "# load smpl model\n",
        "smpl = SMPLModel('./smpl/models/model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load time-varying parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# inputs\n",
        "motionData_path = \"./4D-Humans_outputs/results/demo_biggerspin1.pkl\"\n",
        "main_guy = 1\n",
        "\n",
        "# load motion data\n",
        "motiondata = joblib.load(open(motionData_path, \"rb\"))\n",
        "frames = sorted(list(motiondata.keys()))\n",
        "per_frame_smpl_data = {\"time\":[], \"beta\":[], \"pose\":[], \"position\":[]}\n",
        "for i in range(0, len(frames)):\n",
        "    frame_i = motiondata[frames[i]]\n",
        "    # print(frame_i.keys())\n",
        "    pose_i = frame_i[\"pose\"] # this stores a list of poses for characters in the \n",
        "    center_i = frame_i[\"center\"]\n",
        "    scale_i = frame_i[\"scale\"]\n",
        "    smpl_i = frame_i[\"smpl\"]\n",
        "    ids_i = frame_i['tid']\n",
        "    threeD_joints_i = frame_i['3d_joints']\n",
        "    # only care about the guy of interest\n",
        "    if main_guy not in ids_i:\n",
        "        continue\n",
        "    pose_i_main = pose_i[ids_i.index(main_guy)]\n",
        "    threeD_joints_i_main = threeD_joints_i[ids_i.index(main_guy)] # shape is (43, 3)\n",
        "    smpl_i_main = smpl_i[ids_i.index(main_guy)] # dictionary with keys ['global_orient', 'body_pose', 'betas']\n",
        "    \n",
        "    # get the smpl parameters\n",
        "    global_orient = smpl_i_main[\"global_orient\"] # defined root orentation (rotation matrix )\n",
        "    body_pose = smpl_i_main[\"body_pose\"] # defines the rotation matrix of the 23 joints (generated using Rodrigues formula)\n",
        "    beta = smpl_i_main[\"betas\"] # shape is (10,)\n",
        "    # convert rotation matrices in body pose to axis-angle representation\n",
        "    body_pose_aa = np.zeros((body_pose.shape[0], 3))\n",
        "    for jj in range(body_pose.shape[0]):\n",
        "        body_pose_aa[jj] = cv2.Rodrigues(body_pose[jj])[0].squeeze()\n",
        "    # rotate global_orient by 180 degrees by x axis\n",
        "    # global_orient[0] = cv2.Rodrigues(np.array([np.pi, 0, 0]))[0].squeeze() @ global_orient[0]\n",
        "    global_orient_aa = np.array([cv2.Rodrigues(global_orient[0])[0].squeeze()])\n",
        "    if len(per_frame_smpl_data[\"pose\"]) > 0:\n",
        "        # check for discontinuities in the global orientation\n",
        "        for jj in range(0, len(global_orient_aa[0])):\n",
        "            if np.abs(global_orient_aa[0][jj] - per_frame_smpl_data[\"pose\"][-1][0, jj]) > np.pi/4:\n",
        "                global_orient_aa[0][jj] *= -1\n",
        "    # global_orient_aa[np.where(global_orient_aa > np.pi)] -= 2*np.pi\n",
        "    # global_orient_aa[np.where(global_orient_aa < -np.pi)] += 2*np.pi\n",
        "    body_pose_aa = np.concatenate([global_orient_aa, body_pose_aa], axis=0)\n",
        "    # load data related to smpl model\n",
        "    per_frame_smpl_data[\"time\"].append(frame_i[\"time\"])\n",
        "    per_frame_smpl_data[\"beta\"].append(beta)\n",
        "    per_frame_smpl_data[\"pose\"].append(body_pose_aa)\n",
        "    per_frame_smpl_data[\"position\"].append(np.zeros([3, ]))\n",
        "per_frame_smpl_data[\"beta\"] = np.array(per_frame_smpl_data[\"beta\"])\n",
        "per_frame_smpl_data[\"pose\"] = np.array(per_frame_smpl_data[\"pose\"])\n",
        "per_frame_smpl_data[\"position\"] = np.array(per_frame_smpl_data[\"position\"])\n",
        "per_frame_smpl_data[\"time\"] = np.array(per_frame_smpl_data[\"time\"])\n",
        "\n",
        "per_frame_smpl_data[\"pose_interp\"] = interp1d(per_frame_smpl_data[\"time\"], per_frame_smpl_data[\"pose\"], axis=0, fill_value=\"extrapolate\", bounds_error=False)\n",
        "per_frame_smpl_data[\"beta_interp\"] = interp1d(per_frame_smpl_data[\"time\"], per_frame_smpl_data[\"beta\"], axis=0, fill_value=\"extrapolate\", bounds_error=False)\n",
        "per_frame_smpl_data[\"position_interp\"] = interp1d(per_frame_smpl_data[\"time\"], per_frame_smpl_data[\"position\"], axis=0, fill_value=\"extrapolate\", bounds_error=False)\n",
        "# \n",
        "\n",
        "# print(per_frame_smpl_data[\"beta\"].shape, per_frame_smpl_data[\"pose\"].shape, per_frame_smpl_data[\"position\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize detected mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_mesh():\n",
        "    global mesh_list, params_list, simulator_t\n",
        "    for i in range(0, len(mesh_list)):\n",
        "        beta = params_list[i][\"beta_interp\"](simulator_t)\n",
        "        pose = params_list[i][\"pose_interp\"](simulator_t)\n",
        "        position = params_list[i][\"position_interp\"](simulator_t)\n",
        "        smpl.set_params(beta=beta, pose=pose, trans=position)\n",
        "        mesh_list[i].update_vertex_positions(smpl.verts)\n",
        "# SM1.update_vertex_positions(V1)\n",
        "def guii():\n",
        "    global simulator_t, simulator_to_end_t\n",
        "    # psim.TextUnformatted(\"Some sample text\")\n",
        "    time_changed, simulator_t = psim.SliderFloat(\"time\", simulator_t, v_min=0, v_max=simulator_to_end_t)\n",
        "    if time_changed:\n",
        "        update_mesh()\n",
        "params_list = [per_frame_smpl_data]\n",
        "mesh_list = []\n",
        "ps.set_verbosity(0)\n",
        "ps.set_SSAA_factor(4)\n",
        "ps.set_program_name(\"Interactive Viewer\")\n",
        "ps.set_ground_plane_mode(\"none\")\n",
        "ps.set_view_projection_mode(\"orthographic\")\n",
        "ps.set_autocenter_structures(False)\n",
        "ps.set_autoscale_structures(False)\n",
        "ps.set_front_dir(\"z_front\")\n",
        "ps.set_up_dir(\"neg_y_up\")\n",
        "ps.set_background_color([0, 0, 0])\n",
        "ps.init()\n",
        "simulator_t = 0\n",
        "simulator_to_end_t = params_list[0][\"time\"][-1]\n",
        "# iterate through each clip to create the mesh + load the parameters\n",
        "for i in range(0, len(params_list)):\n",
        "    params = params_list[i]\n",
        "    smpl.set_params(beta=params[\"beta\"][0], pose=params[\"pose\"][0], trans=params[\"position\"][0])\n",
        "    SM_temp = ps.register_surface_mesh(\"original\", smpl.verts, smpl.faces, color=[0.9,0.9,0.9], smooth_shade=True, edge_width=0.25, )\n",
        "    mesh_list.append(SM_temp)\n",
        "\n",
        "ps.set_user_callback(guii)\n",
        "ps.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
